Metadata-Version: 2.1
Name: datasette
Version: 0.64.5
Summary: An open source multi-tool for exploring and publishing data
Home-page: https://datasette.io/
Author: Simon Willison
License: Apache License, Version 2.0
Project-URL: Documentation, https://docs.datasette.io/en/stable/
Project-URL: Changelog, https://docs.datasette.io/en/stable/changelog.html
Project-URL: Live demo, https://latest.datasette.io/
Project-URL: Source code, https://github.com/simonw/datasette
Project-URL: Issues, https://github.com/simonw/datasette/issues
Project-URL: CI, https://github.com/simonw/datasette/actions?query=workflow%3ATest
Classifier: Development Status :: 4 - Beta
Classifier: Framework :: Datasette
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: End Users/Desktop
Classifier: Topic :: Database
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.7
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: asgiref >=3.2.10
Requires-Dist: click >=7.1.1
Requires-Dist: click-default-group >=1.2.3
Requires-Dist: Jinja2 >=2.10.3
Requires-Dist: hupper >=1.9
Requires-Dist: httpx >=0.20
Requires-Dist: pint >=0.9
Requires-Dist: pluggy >=1.0
Requires-Dist: uvicorn >=0.11
Requires-Dist: aiofiles >=0.4
Requires-Dist: janus >=0.6.2
Requires-Dist: asgi-csrf >=0.9
Requires-Dist: PyYAML >=5.3
Requires-Dist: mergedeep >=1.1.1
Requires-Dist: itsdangerous >=1.1
Requires-Dist: setuptools
Requires-Dist: pip
Provides-Extra: docs
Requires-Dist: furo ==2022.9.29 ; extra == 'docs'
Requires-Dist: sphinx-autobuild ; extra == 'docs'
Requires-Dist: codespell ; extra == 'docs'
Requires-Dist: blacken-docs ; extra == 'docs'
Requires-Dist: sphinx-copybutton ; extra == 'docs'
Provides-Extra: rich
Requires-Dist: rich ; extra == 'rich'
Provides-Extra: test
Requires-Dist: pytest >=5.2.2 ; extra == 'test'
Requires-Dist: pytest-xdist >=2.2.1 ; extra == 'test'
Requires-Dist: pytest-asyncio >=0.17 ; extra == 'test'
Requires-Dist: beautifulsoup4 >=4.8.1 ; extra == 'test'
Requires-Dist: black ==22.10.0 ; extra == 'test'
Requires-Dist: blacken-docs ==1.12.1 ; extra == 'test'
Requires-Dist: pytest-timeout >=1.4.2 ; extra == 'test'
Requires-Dist: trustme >=0.7 ; extra == 'test'
Requires-Dist: cogapp >=3.3.0 ; extra == 'test'

<img src="https://datasette.io/static/datasette-logo.svg" alt="Datasette">

[![PyPI](https://img.shields.io/pypi/v/datasette.svg)](https://pypi.org/project/datasette/)
[![Changelog](https://img.shields.io/github/v/release/simonw/datasette?label=changelog)](https://docs.datasette.io/en/stable/changelog.html)
[![Python 3.x](https://img.shields.io/pypi/pyversions/datasette.svg?logo=python&logoColor=white)](https://pypi.org/project/datasette/)
[![Tests](https://github.com/simonw/datasette/workflows/Test/badge.svg)](https://github.com/simonw/datasette/actions?query=workflow%3ATest)
[![Documentation Status](https://readthedocs.org/projects/datasette/badge/?version=latest)](https://docs.datasette.io/en/latest/?badge=latest)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/simonw/datasette/blob/main/LICENSE)
[![docker: datasette](https://img.shields.io/badge/docker-datasette-blue)](https://hub.docker.com/r/datasetteproject/datasette)
[![discord](https://img.shields.io/discord/823971286308356157?label=discord)](https://discord.gg/ktd74dm5mw)

*An open source multi-tool for exploring and publishing data*

Datasette is a tool for exploring and publishing data. It helps people take data of any shape or size and publish that as an interactive, explorable website and accompanying API.

Datasette is aimed at data journalists, museum curators, archivists, local governments, scientists, researchers and anyone else who has data that they wish to share with the world.

[Explore a demo](https://global-power-plants.datasettes.com/global-power-plants/global-power-plants), watch [a video about the project](https://simonwillison.net/2021/Feb/7/video/) or try it out by [uploading and publishing your own CSV data](https://docs.datasette.io/en/stable/getting_started.html#try-datasette-without-installing-anything-using-glitch).

* [datasette.io](https://datasette.io/) is the official project website
* Latest [Datasette News](https://datasette.io/news)
* Comprehensive documentation:Â https://docs.datasette.io/
* Examples: https://datasette.io/examples
* Live demo of current `main` branch: https://latest.datasette.io/
* Questions, feedback or want to talk about the project? Join our [Discord](https://discord.gg/ktd74dm5mw)

Want to stay up-to-date with the project? Subscribe to the [Datasette newsletter](https://datasette.substack.com/) for tips, tricks and news on what's new in the Datasette ecosystem.

## Installation

If you are on a Mac, [Homebrew](https://brew.sh/) is the easiest way to install Datasette:

    brew install datasette

You can also install it using `pip` or `pipx`:

    pip install datasette

Datasette requires Python 3.7 or higher. We also have [detailed installation instructions](https://docs.datasette.io/en/stable/installation.html) covering other options such as Docker.

## Basic usage

    datasette serve path/to/database.db

This will start a web server on port 8001 - visit http://localhost:8001/ to access the web interface.

`serve` is the default subcommand, you can omit it if you like.

Use Chrome on OS X? You can run datasette against your browser history like so:

     datasette ~/Library/Application\ Support/Google/Chrome/Default/History --nolock

Now visiting http://localhost:8001/History/downloads will show you a web interface to browse your downloads data:

![Downloads table rendered by datasette](https://static.simonwillison.net/static/2017/datasette-downloads.png)

## metadata.json

If you want to include licensing and source information in the generated datasette website you can do so using a JSON file that looks something like this:

    {
        "title": "Five Thirty Eight",
        "license": "CC Attribution 4.0 License",
        "license_url": "http://creativecommons.org/licenses/by/4.0/",
        "source": "fivethirtyeight/data on GitHub",
        "source_url": "https://github.com/fivethirtyeight/data"
    }

Save this in `metadata.json` and run Datasette like so:

    datasette serve fivethirtyeight.db -m metadata.json

The license and source information will be displayed on the index page and in the footer. They will also be included in the JSON produced by the API.

## datasette publish

If you have [Heroku](https://heroku.com/) or [Google Cloud Run](https://cloud.google.com/run/) configured, Datasette can deploy one or more SQLite databases to the internet with a single command:

    datasette publish heroku database.db

Or:

    datasette publish cloudrun database.db

This will create a docker image containing both the datasette application and the specified SQLite database files. It will then deploy that image to Heroku or Cloud Run and give you a URL to access the resulting website and API.

See [Publishing data](https://docs.datasette.io/en/stable/publish.html) in the documentation for more details.

## Datasette Lite

[Datasette Lite](https://lite.datasette.io/) is Datasette packaged using WebAssembly so that it runs entirely in your browser, no Python web application server required. Read more about that in the [Datasette Lite documentation](https://github.com/simonw/datasette-lite/blob/main/README.md).
